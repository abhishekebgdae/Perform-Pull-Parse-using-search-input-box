{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b864fa4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, WebDriverException\n",
    "import time\n",
    "import os\n",
    "import openpyxl\n",
    "import random\n",
    "\n",
    "def perform_search(search_query, page_headers):\n",
    "    delay = random.uniform(12,20)\n",
    "    # open the URL in the browser\n",
    "    driver.get('https://patentcenter.uspto.gov/')\n",
    "\n",
    "    search_type = \"Application #\"  # Change this to either \"Application #\" or \"Patents #\"\n",
    "\n",
    "    # Wait for the search dropdown button element to become available\n",
    "    try:\n",
    "        search_dropdown_button = WebDriverWait(driver, 20).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, '//button[@class=\"btn btn-primary dropdown-toggle\"]'))\n",
    "        )\n",
    "        search_dropdown_button.click()\n",
    "    except TimeoutException:\n",
    "        print(\"Timeout: Search dropdown button not found\")\n",
    "        driver.quit()\n",
    "\n",
    "    # Find the search type element and click it\n",
    "    try:\n",
    "        search_type_element = WebDriverWait(driver, 20).until(\n",
    "            EC.element_to_be_clickable((By.XPATH, f'//a[contains(@class, \"dropdown-item\") and text()=\"{search_type}\"]'))\n",
    "        )\n",
    "        search_type_element.click()\n",
    "    except TimeoutException:\n",
    "        print(\"Timeout: Search type element not found\")\n",
    "        driver.quit()\n",
    "\n",
    "    # Wait for the search input element to become available\n",
    "    try:\n",
    "        search_input = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.ID, 'TxtBox_bibData_search_input'))\n",
    "        )\n",
    "        search_input.clear()\n",
    "        search_input.send_keys(search_query)\n",
    "    except TimeoutException:\n",
    "        print(\"Timeout: Search input element not found\")\n",
    "        driver.quit()\n",
    "\n",
    "    # Find the search button element by its class name and click it\n",
    "    try:\n",
    "        search_button = WebDriverWait(driver, 20).until(\n",
    "            EC.element_to_be_clickable((By.CLASS_NAME, 'showSearch-btn'))\n",
    "        )\n",
    "        search_button.click()\n",
    "    except TimeoutException:\n",
    "        print(\"Timeout: Search button not found\")\n",
    "        driver.quit()\n",
    "\n",
    "    time.sleep(delay)\n",
    "\n",
    "    # Save the first page as an HTML file\n",
    "    save_page(page_headers[0])\n",
    "\n",
    "    time.sleep(delay)\n",
    "    # XPath for the next four pages\n",
    "    xpaths = [\n",
    "        '//*[@id=\"link_app-data-continuity\"]',\n",
    "        '//*[@id=\"link_app-data-foriegn-priority\"]',\n",
    "        '//*[@id=\"LeftNavLinks\"]/li[8]',\n",
    "        '//*[@id=\"link_app-data-assignments\"]'\n",
    "    ]\n",
    "\n",
    "    # Save the next four pages\n",
    "    for idx, xpath in enumerate(xpaths):\n",
    "        try:\n",
    "            next_page_element = WebDriverWait(driver, 20).until(\n",
    "                EC.element_to_be_clickable((By.XPATH, xpath))\n",
    "            )\n",
    "            next_page_element.click()\n",
    "            time.sleep(delay)\n",
    "            save_page(page_headers[idx + 1])\n",
    "            time.sleep(delay)\n",
    "        except TimeoutException:\n",
    "            print(f\"Timeout: Page {idx + 2} element not found\")\n",
    "\n",
    "def save_page(page_name):\n",
    "    file_location = r\"C:\\Users\\U6060174\\OneDrive - Clarivate Analytics\\Desktop\\Perform search\\pages\"\n",
    "    file_name = f\"{page_name}.html\"\n",
    "    file_path = os.path.join(file_location, file_name)\n",
    "\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(driver.page_source)\n",
    "\n",
    "chrome_path = r'C:\\Program Files (x86)\\Google\\Chrome\\Application\\chrome.exe'\n",
    "chrome_options = Options()\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "chrome_options.binary_location = chrome_path\n",
    "\n",
    "# create a new Chrome browser instance\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "# Read the Excel sheet\n",
    "excel_file = r\"C:\\Users\\U6060174\\OneDrive - Clarivate Analytics\\Desktop\\Perform search\\input.xlsx\"\n",
    "wb = openpyxl.load_workbook(excel_file)\n",
    "sheet = wb.active\n",
    "\n",
    "# Loop through the rows in the Excel sheet (skipping the header row)\n",
    "for row in range(2, sheet.max_row + 1):\n",
    "    search_query = sheet.cell(row=row, column=1).value\n",
    "    page_headers = [sheet.cell(row=row, column=i).value for i in range(2, 7)]\n",
    "\n",
    "    # Perform the search and save the webpage for the current search query\n",
    "    perform_search(search_query, page_headers)\n",
    "\n",
    "# Close the browser\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47b65a0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error occurred while processing the file for 17199594_Continuity: [Errno 2] No such file or directory: 'C:\\\\Users\\\\U6060174\\\\OneDrive - Clarivate Analytics\\\\Desktop\\\\Perform search\\\\pages\\\\17199594_Continuity.html'\n",
      "Error occurred while processing the file for 17199594_Priority: [Errno 2] No such file or directory: 'C:\\\\Users\\\\U6060174\\\\OneDrive - Clarivate Analytics\\\\Desktop\\\\Perform search\\\\pages\\\\17199594_Priority.html'\n",
      "Error occurred while processing the file for 17199594_Attorney: [Errno 2] No such file or directory: 'C:\\\\Users\\\\U6060174\\\\OneDrive - Clarivate Analytics\\\\Desktop\\\\Perform search\\\\pages\\\\17199594_Attorney.html'\n",
      "Error occurred while processing the file for 17199594_Assignment: [Errno 2] No such file or directory: 'C:\\\\Users\\\\U6060174\\\\OneDrive - Clarivate Analytics\\\\Desktop\\\\Perform search\\\\pages\\\\17199594_Assignment.html'\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Set the path to the Excel file containing the URLs and filenames\n",
    "url_file_path = r'C:\\Users\\U6060174\\OneDrive - Clarivate Analytics\\Desktop\\Perform search\\input.xlsx'\n",
    "\n",
    "# Create an empty dataframe to store the parsed data\n",
    "column_names = []\n",
    "for page_name in ['Application', 'Continuity', 'Priority', 'Attorney', 'Assignment']:\n",
    "    for suffix in ['Name', 'Data', 'Status']:\n",
    "        column_names.append(f\"{page_name}_{suffix}\")\n",
    "\n",
    "df_data = pd.DataFrame(columns=column_names)\n",
    "\n",
    "# Define the columns to be used in the loop\n",
    "columns = ['{Application}', '{Continuity}', '{Priority}', '{Attorney}', '{Assignment}']\n",
    "\n",
    "# Loop through the directories containing the HTML files and parse the HTML\n",
    "for i, row in pd.read_excel(url_file_path).iterrows():\n",
    "    data_row = {}\n",
    "    for column in columns:\n",
    "        name = row[column]\n",
    "        file_path = os.path.join(r'C:\\Users\\U6060174\\OneDrive - Clarivate Analytics\\Desktop\\Perform search\\pages', f'{name}.html')\n",
    "        status = 'Success'  # set default status as success\n",
    "\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                html = f.read()\n",
    "\n",
    "            soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "            text = soup.get_text(separator='\\n')\n",
    "            text = text.replace('<div>', '<div> ')\n",
    "            text = text.replace('\\n', ' \\n')\n",
    "        except Exception as e:\n",
    "            print(f\"Error occurred while processing the file for {name}: {e}\")\n",
    "            text = ''\n",
    "            status = 'Error'  # set status as error if there's an exception\n",
    "\n",
    "        column_prefix = column.strip('{}')\n",
    "        data_row[f\"{column_prefix}_Name\"] = name\n",
    "        data_row[f\"{column_prefix}_Data\"] = text\n",
    "        data_row[f\"{column_prefix}_Status\"] = status\n",
    "\n",
    "    df_data = pd.concat([df_data, pd.DataFrame(data_row, index=[0])])\n",
    "\n",
    "# Write the parsed data to an Excel file\n",
    "output_file_path = r'C:\\Users\\U6060174\\OneDrive - Clarivate Analytics\\Desktop\\Perform search\\parsed_data.xlsx'\n",
    "df_data.to_excel(output_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d39e01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d43c331",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ba9371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd1e505",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
